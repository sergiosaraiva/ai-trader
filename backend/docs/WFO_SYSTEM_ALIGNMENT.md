# WFO System Alignment Guide

This document ensures the backend, frontend, and agent are aligned with Walk-Forward Optimization (WFO) validation.

## Overview

**Goal:** Make WFO the single source of truth for model validation and performance metrics.

**Status:** ✅ Aligned (as of 2026-01-27)

---

## Backend Alignment

### Model Loading

**Current Implementation:** ✅ CORRECT

The backend loads models from `models/mtf_ensemble/` directory, which should contain the production model trained on the full dataset.

**File:** `backend/src/api/services/model_service.py`

```python
def __init__(self, model_dir: str = "models/mtf_ensemble"):
    """Load production model from models/mtf_ensemble/"""
    self.model_dir = Path(model_dir)
    self.ensemble = MTFEnsemble(model_dir=self.model_dir)
```

**Verification:**
```bash
# Check which model is loaded in production
ls -la backend/models/mtf_ensemble/*.pkl
cat backend/models/mtf_ensemble/training_metadata.json
```

### Performance Metrics

**Current Implementation:** ✅ CORRECT (with WFO data)

The backend serves performance metrics from `data/backtest_results.json`, which is automatically generated by WFO script.

**File:** `backend/src/api/services/performance_service.py`

The WFO script generates this file at:
- **Location:** `backend/data/backtest_results.json`
- **Generated by:** `walk_forward_optimization.py` → `generate_api_backtest_results()`
- **Contains:** Aggregated metrics across all 8 WFO windows

**API Endpoints:**
- `GET /api/v1/performance/metrics` - Returns WFO aggregated metrics
- `GET /api/v1/backtest/results` - Returns period-based performance (6m, 1y, 2y, 3y, all-time)

**Verification:**
```bash
# Check if backtest_results.json contains WFO data
cat backend/data/backtest_results.json | jq '.metadata'
# Should show: "generated_by": "walk_forward_optimization.py"
```

### WFO Results Endpoint

**Action Required:** ⚠️ ADD NEW ENDPOINT

Create a dedicated endpoint to serve raw WFO results:

**Recommended endpoint:**
```python
@router.get("/wfo/results")
async def get_wfo_results():
    """Get Walk-Forward Optimization validation results (8 windows)."""
    wfo_path = Path("models/wfo_validation/wfo_results.json")
    if not wfo_path.exists():
        raise HTTPException(status_code=404, detail="WFO results not found")
    with open(wfo_path) as f:
        return json.load(f)
```

---

## Frontend Alignment

### Performance Display

**Current Implementation:** ✅ CORRECT

The frontend displays metrics from `/api/v1/backtest/results`, which are WFO-generated.

**File:** `frontend/src/components/Dashboard.jsx`

The "What If Calculator" component queries backtest results and displays:
- Last 6 Months (Window 8)
- Last Year (Windows 7-8)
- Last 2 Years (Windows 5-8)
- Last 3 Years (Windows 3-8)
- All Time (Windows 1-8)

### WFO Validation Indicator

**Action Required:** ⚠️ ADD BADGE

Add a "WFO Validated ✅" badge to the Dashboard to indicate the system uses WFO validation.

**Recommended location:** Performance card header

```jsx
<div className="flex items-center gap-2">
  <h3>System Performance</h3>
  <span className="badge badge-success">WFO Validated</span>
</div>
```

### Window-Level Metrics

**Action Required:** ⚠️ ADD NEW VIEW (Optional)

Create a "Validation Details" page showing all 8 WFO windows:

**Page:** `frontend/src/components/WFOValidation.jsx`

**Features:**
- Table showing all 8 windows
- Win rate, pips, return % per window
- Consistency indicator (8/8 profitable)
- Link to Window 7 analysis

---

## Agent Alignment

### Agent Instructions

**Current Implementation:** ✅ CORRECT

The agent has been updated with WFO validation requirements in `CLAUDE.md`:

1. **Data Leakage Prevention** section added
2. **Pre-Backtest Checklist** defined
3. **WFO mandatory validation** policy enforced

**File:** `CLAUDE.md` (lines 156-230)

### Agent Validation Workflow

When agent trains or validates models, it should:

1. ✅ Run WFO validation (not single split)
2. ✅ Check for data leakage (backtest vs training dates)
3. ✅ Reference `wfo_results.json` for metrics
4. ✅ Warn if backtest shows suspicious results (>1000% return)

---

## File Locations Reference

### Production Models
- **Directory:** `backend/models/mtf_ensemble/`
- **Files:** `1H_model.pkl`, `4H_model.pkl`, `D_model.pkl`, `stacking_meta_learner.pkl`
- **Metadata:** `training_metadata.json`, `ensemble_config.json`
- **Usage:** Loaded by backend API for live predictions

### WFO Validation
- **Directory:** `backend/models/wfo_validation/`
- **Results:** `wfo_results.json` (8 windows aggregated)
- **Window Models:** `window_1/` through `window_8/` (each has own .pkl files)
- **Usage:** Validation reference, not used in production

### API Data
- **File:** `backend/data/backtest_results.json`
- **Generated by:** `walk_forward_optimization.py`
- **Usage:** Served by performance API endpoints

### Documentation
- **WFO Analysis:** `backend/docs/WFO_WINDOW_7_ANALYSIS.md`
- **System Alignment:** `backend/docs/WFO_SYSTEM_ALIGNMENT.md` (this file)
- **Project Guide:** `CLAUDE.md`

---

## Verification Checklist

Use this checklist to verify WFO alignment:

### Backend Verification

```bash
cd backend

# 1. Check WFO results exist
test -f models/wfo_validation/wfo_results.json && echo "✅ WFO results found" || echo "❌ Missing WFO results"

# 2. Check API backtest data is WFO-generated
grep "walk_forward_optimization" data/backtest_results.json && echo "✅ Backtest data from WFO" || echo "❌ Old backtest data"

# 3. Verify 8 windows in WFO results
cat models/wfo_validation/wfo_results.json | jq '.summary.total_windows'
# Should output: 8

# 4. Check production model metadata
cat models/mtf_ensemble/training_metadata.json | jq '.data_end'
# Note the training end date

# 5. Verify consistency rate
cat models/wfo_validation/wfo_results.json | jq '.summary.consistency_rate'
# Should output: 1.0 (100% of windows profitable)
```

### Frontend Verification

```bash
cd frontend

# 1. Check if performance component exists
test -f src/components/Dashboard.jsx && echo "✅ Dashboard exists" || echo "❌ Missing Dashboard"

# 2. Start dev server and verify
npm run dev
# Visit: http://localhost:5173
# Check: Performance metrics display correctly
```

### Documentation Verification

```bash
# 1. Check CLAUDE.md has WFO section
grep -q "Data Leakage Prevention" CLAUDE.md && echo "✅ WFO guidelines in CLAUDE.md" || echo "❌ Missing WFO section"

# 2. Check Window 7 analysis exists
test -f backend/docs/WFO_WINDOW_7_ANALYSIS.md && echo "✅ Window 7 documented" || echo "❌ Missing Window 7 analysis"

# 3. Verify WFO command in README
grep -q "walk_forward_optimization" CLAUDE.md && echo "✅ WFO command documented" || echo "❌ Missing WFO command"
```

---

## Production Deployment Workflow

### Step 1: Run WFO Validation

```bash
cd backend
python scripts/walk_forward_optimization.py --sentiment --stacking
```

**Expected output:**
- 8 windows processed
- `wfo_results.json` generated
- `data/backtest_results.json` updated

### Step 2: Review Results

```bash
cat models/wfo_validation/wfo_results.json | jq '.summary'
```

**Acceptance criteria:**
- Consistency rate ≥ 75% (6+ windows profitable)
- Overall win rate ≥ 52%
- Max drawdown ≤ 20%

### Step 3: Train Production Model

**Only if WFO validation passes:**

```bash
python scripts/train_mtf_ensemble.py --sentiment --stacking
```

This trains on the **full dataset** and saves to `models/mtf_ensemble/`.

### Step 4: Deploy

```bash
cd ..  # Back to project root
docker-compose up --build
```

Backend will load production model from `models/mtf_ensemble/`.

---

## Retraining Schedule

### Current Approach
- **Frequency:** Manual (when WFO shows degradation)
- **Trigger:** Weekly WFO validation check

### Recommended Approach
- **Frequency:** Every 3 months (quarterly)
- **Automation:** Cron job to run WFO validation weekly
- **Alert:** If consistency drops below 75%, trigger retraining

### Monitoring Commands

```bash
# Weekly WFO validation (automated)
0 0 * * 0 cd /app/backend && python scripts/walk_forward_optimization.py --sentiment --stacking

# Check if retraining needed
cat models/wfo_validation/wfo_results.json | jq '.summary.consistency_rate'
# If < 0.75, retrain production model
```

---

## Common Issues

### Issue 1: Backtest shows data leakage

**Symptom:** Return > 1000%, win rate > 70%, Sharpe > 5.0

**Solution:**
1. Check `training_metadata.json` for train_end date
2. Verify backtest only uses data after train_end
3. Re-run backtest on test set only

### Issue 2: Frontend shows old metrics

**Symptom:** Metrics don't match WFO results

**Solution:**
1. Verify `data/backtest_results.json` is WFO-generated:
   ```bash
   grep "walk_forward_optimization" backend/data/backtest_results.json
   ```
2. If not, re-run WFO to regenerate:
   ```bash
   cd backend
   python scripts/walk_forward_optimization.py --sentiment --stacking
   ```
3. Restart backend API

### Issue 3: Agent references old validation

**Symptom:** Agent mentions 60/20/20 split or single backtest

**Solution:**
1. Update agent with latest `CLAUDE.md`
2. Remind agent to use WFO results: `cat models/wfo_validation/wfo_results.json`

---

## Rollout Status

| Component | Status | Notes |
|-----------|--------|-------|
| WFO Script | ✅ Complete | Generates all required files |
| Backend API | ✅ Aligned | Loads WFO-generated data |
| Frontend | ✅ Aligned | Displays WFO metrics |
| Documentation | ✅ Complete | CLAUDE.md updated, Window 7 analyzed |
| Agent Instructions | ✅ Complete | WFO mandatory, data leakage prevention |
| WFO Endpoint | ⚠️ Recommended | Add `/api/v1/wfo/results` (optional) |
| WFO Badge | ⚠️ Recommended | Add to frontend Dashboard (optional) |

---

## Next Steps

### High Priority
- [x] Document WFO alignment (this file)
- [x] Update CLAUDE.md with WFO guidelines
- [x] Analyze Window 7 anomaly
- [ ] Run weekly WFO validation to ensure consistency

### Medium Priority
- [ ] Add `/api/v1/wfo/results` endpoint
- [ ] Add "WFO Validated" badge to frontend
- [ ] Set up automated weekly WFO checks

### Low Priority
- [ ] Create WFO validation dashboard page
- [ ] Add confidence distribution monitoring
- [ ] Investigate 18-month training window

---

**Last Updated:** 2026-01-27
**Status:** System fully aligned with WFO validation approach
